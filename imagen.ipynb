{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing necessary data"
      ],
      "metadata": {
        "id": "Y-qGe-B_eFdT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "EvFObpqF5iu-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e723c755-8aff-454e-8a75-34ec02b56955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/volodymyrpivoshenko/pixel-characters-dataset\n",
            "License(s): CC-BY-SA-3.0\n",
            "pixel-characters-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  pixel-characters-dataset.zip\n",
            "replace data/0/0.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ],
      "source": [
        "! kaggle datasets download -d volodymyrpivoshenko/pixel-characters-dataset\n",
        "! unzip \"pixel-characters-dataset.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Libraries, parameters and data path"
      ],
      "metadata": {
        "id": "-FD6OAZdeJ4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "data_dir = \"/content/data\"\n",
        "img_size = 64\n",
        "channels = 3\n",
        "latent_dim = 128\n",
        "batch_size = 64\n",
        "epochs = 20000\n",
        "save_interval = 1000"
      ],
      "metadata": {
        "id": "FfsU-MmieKO1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data loading"
      ],
      "metadata": {
        "id": "Yc7xunQLeKiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images(data_dir):\n",
        "    images = []\n",
        "    for folder in range(4):\n",
        "        folder_path = os.path.join(data_dir, str(folder))\n",
        "        if os.path.isdir(folder_path):\n",
        "            for img_file in tqdm(os.listdir(folder_path)):\n",
        "                img_path = os.path.join(folder_path, img_file)\n",
        "                img = load_img(img_path, target_size=(img_size, img_size))\n",
        "                img = img_to_array(img)\n",
        "                img = (img - 127.5) / 127.5\n",
        "                images.append(img)\n",
        "    return np.array(images)\n",
        "print(\"Loading dataset...\")\n",
        "images = load_images(data_dir)\n",
        "print(f\"Dataset loaded with shape: {images.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HN7javnieK26",
        "outputId": "373b89f8-a1ae-4df6-e3e1-5cbda12b900b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 912/912 [00:00<00:00, 3365.72it/s]\n",
            "100%|██████████| 912/912 [00:00<00:00, 3063.50it/s]\n",
            "100%|██████████| 912/912 [00:00<00:00, 2786.76it/s]\n",
            "100%|██████████| 912/912 [00:00<00:00, 3065.77it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "XgUcJqemeLM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(8*8*256, input_dim=latent_dim))\n",
        "    model.add(layers.Reshape((8, 8, 256)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Conv2DTranspose(32, kernel_size=4, strides=2, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Conv2DTranspose(channels, kernel_size=4, strides=2, padding='same', activation='tanh'))\n",
        "    return model\n",
        "def build_discriminator():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, kernel_size=4, strides=2, input_shape=(img_size, img_size, channels), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Conv2D(128, kernel_size=4, strides=2, padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Conv2D(256, kernel_size=4, strides=2, padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Conv2D(512, kernel_size=4, strides=2, padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dropout(0.4))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "def build_gan(generator, discriminator):\n",
        "    discriminator.trainable = False\n",
        "    model = tf.keras.Sequential([generator, discriminator])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "eQ27pRufeLhv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling the model"
      ],
      "metadata": {
        "id": "n1W3iGube5PF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "discriminator.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "gan = build_gan(generator, discriminator)\n",
        "gan.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy')\n"
      ],
      "metadata": {
        "id": "0EMoiRr3e0jJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model and saving images"
      ],
      "metadata": {
        "id": "5nI4y2pMeLzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_noise(batch_size, latent_dim):\n",
        "    return np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "def save_images(epoch, generator, examples=5):\n",
        "    noise = sample_noise(examples, latent_dim)\n",
        "    generated_images = generator.predict(noise)\n",
        "    generated_images = 0.5 * generated_images + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(1, examples, figsize=(15, 15))\n",
        "    for i in range(examples):\n",
        "        axs[i].imshow(generated_images[i])\n",
        "        axs[i].axis('off')\n",
        "    plt.show()\n",
        "def train(epochs, batch_size, save_interval):\n",
        "    valid = np.ones((batch_size, 1))\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        idx = np.random.randint(0, images.shape[0], batch_size)\n",
        "        real_imgs = images[idx]\n",
        "\n",
        "        noise = sample_noise(batch_size, latent_dim)\n",
        "        gen_imgs = generator.predict(noise)\n",
        "\n",
        "        d_loss_real = discriminator.train_on_batch(real_imgs, valid)\n",
        "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        noise = sample_noise(batch_size, latent_dim)\n",
        "        g_loss = gan.train_on_batch(noise, valid)\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print(f\"{epoch} [D loss: {d_loss[0]}, acc.: {100 * d_loss[1]}%] [G loss: {g_loss}]\")\n",
        "\n",
        "        if epoch % save_interval == 0:\n",
        "            save_images(epoch, generator)\n",
        "train(epochs, batch_size, save_interval)\n"
      ],
      "metadata": {
        "id": "JUqi37bpeMDV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}